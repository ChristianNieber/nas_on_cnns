{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from analyse_best import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T11:33:37.405789200Z",
     "start_time": "2024-06-04T11:33:34.572009600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95-1 1.96596 final: 0.98740 acc: 0.98829 p: 7878\n",
      "\u001B[1mlearning:adam lr:0.0014285518469096664 beta1:0.620055539105466 beta2:0.8173796436975189 batch_size:182\u001B[0m\n",
      "114-0 1.95683 final: 0.98690 acc: 0.99000 p: 11054 σ: 0.4339\n",
      "\u001B[1mlearning:gradient-descent lr:0.04571493539828184 momentum:0.9492879047138598 nesterov:True batch_size:289\u001B[0m\n",
      "159-4 1.85054 final: 0.98190 acc: 0.98829 p: 11465\n",
      "\u001B[1mlearning:gradient-descent lr:0.08344280883533843 momentum:0.7710641198599785 nesterov:True batch_size:317\u001B[0m\n",
      "109-3 1.84760 final: 0.98590 acc: 0.98800 p: 11030 σ: 0.4044\n",
      "\u001B[1mlearning:gradient-descent lr:0.01708134045831386 momentum:0.9428412217440515 nesterov:True batch_size:245\u001B[0m\n",
      "188-3 1.79152 final: 0.98540 acc: 0.98800 p: 12773 σ: 0.4585\n",
      "\u001B[1mlearning:gradient-descent lr:0.060521523085010125 momentum:0.8131233290371582 nesterov:True batch_size:370\u001B[0m\n",
      "65-2 1.70874 final: 0.98660 acc: 0.98686 p: 13113 σ: 0.4443\n",
      "\u001B[1mlearning:gradient-descent lr:0.07215084659748487 momentum:0.7758798944659643 nesterov:True batch_size:208\u001B[0m\n",
      "111-4 1.67642 final: 0.98580 acc: 0.98514 p: 10388 σ: 0.5000\n",
      "\u001B[1mlearning:gradient-descent lr:0.04179708677573802 momentum:0.8589462826308558 nesterov:False batch_size:280\u001B[0m\n",
      "140-2 1.65042 final: 0.98290 acc: 0.98486 p: 10530 σ: 0.3688\n",
      "\u001B[1mlearning:gradient-descent lr:0.0833362147995156 momentum:0.7196593254499506 nesterov:False batch_size:204\u001B[0m\n",
      "67-4 1.64036 final: 0.98510 acc: 0.98543 p: 12162\n",
      "\u001B[1mlearning:gradient-descent lr:0.06425560430393837 momentum:0.8287137778769207 nesterov:True batch_size:285\u001B[0m\n",
      "100-3 1.62828 final: 0.98080 acc: 0.98429 p: 9848\n",
      "\u001B[1mlearning:gradient-descent lr:0.0726563233930893 momentum:0.8202513367616876 nesterov:True batch_size:365\u001B[0m\n",
      "121-2 1.52114 final: 0.98250 acc: 0.98514 p: 15214 σ: 0.3759\n",
      "\u001B[1mlearning:gradient-descent lr:0.08239739131988974 momentum:0.8269737592835477 nesterov:False batch_size:581\u001B[0m\n",
      "90-4 1.49475 final: 0.98420 acc: 0.98486 p: 15368 σ: 0.2912\n",
      "\u001B[1mlearning:gradient-descent lr:0.08784207702078572 momentum:0.7273301305581111 nesterov:True batch_size:304\u001B[0m\n",
      "158-1 1.42659 final: 0.98180 acc: 0.98657 p: 21292 σ: 0.4420\n",
      "\u001B[1mlearning:gradient-descent lr:0.07781700225483079 momentum:0.7110541433456422 nesterov:True batch_size:627\u001B[0m\n",
      "47-3 1.40522 final: 0.98230 acc: 0.98457 p: 17472 σ: 0.3789\n",
      "\u001B[1mlearning:gradient-descent lr:0.09631199003787534 momentum:0.7810455778094387 nesterov:True batch_size:338\u001B[0m\n",
      "179-2 1.40160 final: 0.98690 acc: 0.98600 p: 20851\n",
      "\u001B[1mlearning:gradient-descent lr:0.04690919138985609 momentum:0.8221188223976067 nesterov:True batch_size:390\u001B[0m\n",
      "149-4 1.37955 final: 0.98240 acc: 0.98257 p: 13164\n",
      "\u001B[1mlearning:gradient-descent lr:0.035653997852641915 momentum:0.8713939998439085 nesterov:True batch_size:354\u001B[0m\n",
      "192-2 1.36287 final: 0.98220 acc: 0.98086 p: 8811\n",
      "\u001B[1mlearning:gradient-descent lr:0.07222792539497125 momentum:0.7012825530042479 nesterov:False batch_size:296\u001B[0m\n",
      "199-3 1.35901 final: 0.98480 acc: 0.98229 p: 13022 σ: 0.4071\n",
      "\u001B[1mlearning:gradient-descent lr:0.05336484084577606 momentum:0.8018699196543946 nesterov:False batch_size:457\u001B[0m\n",
      "144-0 1.31568 final: 0.98320 acc: 0.98200 p: 13576 σ: 0.3176\n",
      "\u001B[1mlearning:gradient-descent lr:0.06461178919055638 momentum:0.8467231184454271 nesterov:True batch_size:476\u001B[0m\n",
      "197-0 1.31246 final: 0.98600 acc: 0.98714 p: 26006\n",
      "\u001B[1mlearning:gradient-descent lr:0.04354783781201832 momentum:0.9259965634559341 nesterov:True batch_size:717\u001B[0m\n",
      "\u001B[1m1 physical GPUs, 1 logical GPUs\u001B[0m\n",
      "              lr  batch_size   momentum\n",
      "count  20.000000   20.000000  19.000000\n",
      "mean    0.060153  364.250000   0.815556\n",
      "std     0.024485  143.292808   0.073982\n",
      "min     0.001429  182.000000   0.701283\n",
      "25%     0.045173  283.750000   0.773472\n",
      "50%     0.064434  327.500000   0.820251\n",
      "75%     0.078962  406.750000   0.852835\n",
      "max     0.096312  717.000000   0.949288\n"
     ]
    },
    {
     "data": {
      "text/plain": "            learning        lr              beta1               beta2  \\\n0               adam  0.001429  0.620055539105466  0.8173796436975189   \n1   gradient-descent  0.045715                NaN                 NaN   \n2   gradient-descent  0.083443                NaN                 NaN   \n3   gradient-descent  0.017081                NaN                 NaN   \n4   gradient-descent  0.060522                NaN                 NaN   \n5   gradient-descent  0.072151                NaN                 NaN   \n6   gradient-descent  0.041797                NaN                 NaN   \n7   gradient-descent  0.083336                NaN                 NaN   \n8   gradient-descent  0.064256                NaN                 NaN   \n9   gradient-descent  0.072656                NaN                 NaN   \n10  gradient-descent  0.082397                NaN                 NaN   \n11  gradient-descent  0.087842                NaN                 NaN   \n12  gradient-descent  0.077817                NaN                 NaN   \n13  gradient-descent  0.096312                NaN                 NaN   \n14  gradient-descent  0.046909                NaN                 NaN   \n15  gradient-descent  0.035654                NaN                 NaN   \n16  gradient-descent  0.072228                NaN                 NaN   \n17  gradient-descent  0.053365                NaN                 NaN   \n18  gradient-descent  0.064612                NaN                 NaN   \n19  gradient-descent  0.043548                NaN                 NaN   \n\n    batch_size  momentum nesterov  \n0          182       NaN      NaN  \n1          289  0.949288     True  \n2          317  0.771064     True  \n3          245  0.942841     True  \n4          370  0.813123     True  \n5          208  0.775880     True  \n6          280  0.858946    False  \n7          204  0.719659    False  \n8          285  0.828714     True  \n9          365  0.820251     True  \n10         581  0.826974    False  \n11         304  0.727330     True  \n12         627  0.711054     True  \n13         338  0.781046     True  \n14         390  0.822119     True  \n15         354  0.871394     True  \n16         296  0.701283    False  \n17         457  0.801870    False  \n18         476  0.846723     True  \n19         717  0.925997     True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>learning</th>\n      <th>lr</th>\n      <th>beta1</th>\n      <th>beta2</th>\n      <th>batch_size</th>\n      <th>momentum</th>\n      <th>nesterov</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>adam</td>\n      <td>0.001429</td>\n      <td>0.620055539105466</td>\n      <td>0.8173796436975189</td>\n      <td>182</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gradient-descent</td>\n      <td>0.045715</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>289</td>\n      <td>0.949288</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>gradient-descent</td>\n      <td>0.083443</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>317</td>\n      <td>0.771064</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>gradient-descent</td>\n      <td>0.017081</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>245</td>\n      <td>0.942841</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>gradient-descent</td>\n      <td>0.060522</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>370</td>\n      <td>0.813123</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>gradient-descent</td>\n      <td>0.072151</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>208</td>\n      <td>0.775880</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>gradient-descent</td>\n      <td>0.041797</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>280</td>\n      <td>0.858946</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>gradient-descent</td>\n      <td>0.083336</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>204</td>\n      <td>0.719659</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>gradient-descent</td>\n      <td>0.064256</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>285</td>\n      <td>0.828714</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>gradient-descent</td>\n      <td>0.072656</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>365</td>\n      <td>0.820251</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>gradient-descent</td>\n      <td>0.082397</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>581</td>\n      <td>0.826974</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>gradient-descent</td>\n      <td>0.087842</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>304</td>\n      <td>0.727330</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>gradient-descent</td>\n      <td>0.077817</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>627</td>\n      <td>0.711054</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>gradient-descent</td>\n      <td>0.096312</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>338</td>\n      <td>0.781046</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>gradient-descent</td>\n      <td>0.046909</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>390</td>\n      <td>0.822119</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>gradient-descent</td>\n      <td>0.035654</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>354</td>\n      <td>0.871394</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>gradient-descent</td>\n      <td>0.072228</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>296</td>\n      <td>0.701283</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>gradient-descent</td>\n      <td>0.053365</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>457</td>\n      <td>0.801870</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>gradient-descent</td>\n      <td>0.064612</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>476</td>\n      <td>0.846723</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>gradient-descent</td>\n      <td>0.043548</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>717</td>\n      <td>0.925997</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show statistics on learning optimizer of 10 best individuals over different experiments\n",
    "df = learning_stats(num_individuals=20, list_population=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T11:33:38.942156200Z",
     "start_time": "2024-06-04T11:33:37.408781100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1 physical GPUs, 1 logical GPUs\u001B[0m\n",
      "              lr  batch_size   momentum\n",
      "count  20.000000   20.000000  19.000000\n",
      "mean    0.060153  364.250000   0.815556\n",
      "std     0.024485  143.292808   0.073982\n",
      "min     0.001429  182.000000   0.701283\n",
      "25%     0.045173  283.750000   0.773472\n",
      "50%     0.064434  327.500000   0.820251\n",
      "75%     0.078962  406.750000   0.852835\n",
      "max     0.096312  717.000000   0.949288\n"
     ]
    }
   ],
   "source": [
    "df = learning_stats(20)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T11:33:39.744041800Z",
     "start_time": "2024-06-04T11:33:38.873339100Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
